{"cells":[{"cell_type":"markdown","source":["## Task 1: Spark SQL (15m)"],"metadata":{"id":"yvjBmGBAxnQc","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"36b565b0-dc53-4172-b646-4c82e1c472be","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"metadata":{"id":"MkbrHZYEw5Cr","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"30d54257-dc20-4174-aa40-84e1f6abc56f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sales_file_location = \"/FileStore/tables/Sales_table.csv\"\nproducts_file_location = \"/FileStore/tables/Products_table.csv\"\nsellers_file_location = \"/FileStore/tables/Sellers_table.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\nproducts_table = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(products_file_location)\n\nsales_table = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(sales_file_location)\n\nsellers_table = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(sellers_file_location)"],"metadata":{"id":"2luSAeOXxBiQ","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5607f10e-0a58-4330-bbeb-fa1d6863efb1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# (a) Output the top 3 most popular products sold among all sellers [2m]\n# Your table should have 1 column(s): [product_name]\n\n# create view to use with SQL queries\nproducts_table.createOrReplaceTempView(\"products_table\")\nsales_table.createOrReplaceTempView(\"sales_table\")\n\n\n# Join the products and sales together\n# Then group it and get the total sales per product \nspark.sql(\"\"\"\nselect p.product_name\nfrom products_table p join sales_table s\non s.product_id = p.product_id\ngroup by p.product_name\norder by sum(s.num_of_items_sold) desc\nlimit 3\n\"\"\").show()\n\n\n\n\n\n"],"metadata":{"id":"Ps_v7oTixnQf","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7fb33021-930c-4fa9-b595-4ed83c279ed4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+\n| product_name|\n+-------------+\n|product_51270|\n|product_18759|\n|product_59652|\n+-------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# (b) Find out the total sales of the products sold by sellers 1 to 10 and output the top most sold product [2m]\n# Your table should have 1 column(s): [product_name]\n\n# create view to use with SQL queries\nproducts_table.createOrReplaceTempView(\"products_table\")\nsales_table.createOrReplaceTempView(\"sales_table\")\n\n# Inner query gets the product_id of the most sold product\n# Group by product_id as it is also unique and sales_table has no product_name\n# Outer query gets the product_name\n\nspark.sql(\"\"\"\nselect product_name \nfrom products_table\nwhere product_id = \n\n(\nselect product_id\nfrom sales_table\nwhere seller_id <= 10\ngroup by product_id\norder by sum(num_of_items_sold) desc\nlimit 1\n\n)\n\"\"\").show()"],"metadata":{"id":"Ljmb_1OaxC8Q","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"866983b3-8214-4740-8f4d-90e87d1db482","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+-------------+\n| product_name|\n+-------------+\n|product_36658|\n+-------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# (c) Compute the combined revenue earned from sellers where seller_id ranges from 1 to 500 inclusive. [3m]\n# Your table should have 1 column(s): [total_revenue]\n\n\n# create view to use with SQL queries\nproducts_table.createOrReplaceTempView(\"products_table\")\nsales_table.createOrReplaceTempView(\"sales_table\")\n\n# For explaination\n# Gets only the rows where seller_id is within range\n# spark.sql(\"\"\"\n# select *\n# from sales_table s join products_table p \n# on s.product_id = p.product_id\n# where s.seller_id <= 500;\n\n# \"\"\").show(10)\n\n\n# For each row, just sum up the num_of_items * price\nspark.sql(\"\"\"\nselect sum(s.num_of_items_sold * p.price) as total_revenue\nfrom sales_table s join products_table p \non s.product_id = p.product_id\nwhere s.seller_id <= 500;\n\n\"\"\").show()\n\n\n"],"metadata":{"id":"QtinRRycxDBS","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fa7bec8e-f93d-48ff-af38-d395c6fe7422","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+--------+----------+---------+-----------------+----------+-------------+-----+\n|order_id|product_id|seller_id|num_of_items_sold|product_id| product_name|price|\n+--------+----------+---------+-----------------+----------+-------------+-----+\n|     126|     68948|       71|              432|     68948|product_68948|  144|\n|     203|     76129|      235|              266|     76129|product_76129|   51|\n|     269|     82862|      478|              873|     82862|product_82862|   37|\n|     304|     50640|      186|              326|     50640|product_50640|  161|\n|     353|     58622|      281|              790|     58622|product_58622|  139|\n|     387|       560|      120|              821|       560|  product_560|   86|\n|     450|     88244|      388|              411|     88244|product_88244|  177|\n|     596|     30662|      391|              401|     30662|product_30662|   49|\n|     651|     78967|      410|              833|     78967|product_78967|   95|\n|     677|     10209|      131|              969|     10209|product_10209|   58|\n+--------+----------+---------+-----------------+----------+-------------+-----+\nonly showing top 10 rows\n\n+-------------+\n|total_revenue|\n+-------------+\n|    160916699|\n+-------------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# (d) Among sellers with rating >= 4 who have achieved a combined number of products sold >= 3000, find out the top 10 most expensive product sold by any of the sellers. (If there are multiple products at the same price, please sort them in ascending order of product_id) [8m]\n# Your table should have 1 column(s): [product_name]\n# To get the full mark, your query should not run for more than 1 min\n\n\nsellers_table.createOrReplaceTempView(\"sellers_table\")\nproducts_table.createOrReplaceTempView(\"products_table\")\nsales_table.createOrReplaceTempView(\"sales_table\")\n\n\n# For explanation\n\n# Get the list of valid sellers\n# spark.sql(\"\"\"\n# (\n# select s.seller_id\n#   from sales_table s\n#   join sellers_table sl \n#   on s.seller_id = sl.seller_id\n#   where sl.rating >=4\n#   group by s.seller_id\n#   having sum(s.num_of_items_sold) >= 3000\n# )  \n# \"\"\").show()\n\n\n# spark.sql(\"\"\"\n# select *\n# from products_table p join sales_table s\n# on p.product_id = s.product_id\n# where s.seller_id in \n# (\n# select s.seller_id\n#   from sales_table s\n#   join sellers_table sl \n#   on s.seller_id = sl.seller_id\n#   where sl.rating >=4\n#   group by s.seller_id\n#   having sum(s.num_of_items_sold) >= 3000\n# )  \n# order by p.product_id asc\n# limit 10\n# \"\"\").show()\n\n\n\nspark.sql(\"\"\"\nselect p.product_name\nfrom products_table p join sales_table s\non p.product_id = s.product_id\nwhere s.seller_id in \n(\nselect s.seller_id\n  from sales_table s\n  join sellers_table sl \n  on s.seller_id = sl.seller_id\n  where sl.rating >=4\n  group by s.seller_id\n  having sum(s.num_of_items_sold) >= 3000\n)  \ngroup by p.product_name, p.price, p.product_id\norder by p.price desc, p.product_id asc\nlimit 10\n\"\"\").show()\n\n\n# For testing\n# spark.sql(\"\"\"\n# select *\n# from sales_table join products_table on sales_table.product_id = products_table.product_id\n# where seller_id in \n# (\n# select s.seller_id\n#   from sales_table s\n#   join sellers_table sl \n#   on s.seller_id = sl.seller_id\n#   where sl.rating >=4\n#   group by s.seller_id\n#   having sum(s.num_of_items_sold) >= 3000\n# )  \n# and seller_id = \"47823\"\n# \"\"\").show()\n\n\n\n\n\n\n\n"],"metadata":{"id":"jdG80LVMxnQf","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"59c00e0a-34de-4614-b783-71beb7503716","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---------+\n|seller_id|\n+---------+\n|    41751|\n|    18979|\n|     1591|\n|    40574|\n|    49308|\n|    12940|\n|    45011|\n|    49855|\n|    40011|\n|    47084|\n|    21700|\n|    18866|\n|    13285|\n|      471|\n|      148|\n|    45307|\n|    46465|\n|    46943|\n|    26706|\n|      833|\n+---------+\nonly showing top 20 rows\n\n+----------+------------+-----+--------+----------+---------+-----------------+\n|product_id|product_name|price|order_id|product_id|seller_id|num_of_items_sold|\n+----------+------------+-----+--------+----------+---------+-----------------+\n|         3|   product_3|  147|  241776|         3|    38710|              484|\n|         3|   product_3|  147|  183426|         3|    42730|              224|\n|         5|   product_5|   13|   51484|         5|    46959|              409|\n|         5|   product_5|   13|   14481|         5|    45359|              725|\n|         5|   product_5|   13|  256866|         5|    47593|              547|\n|         9|   product_9|   70|   13981|         9|    27118|              977|\n|         9|   product_9|   70|  260296|         9|    30746|              902|\n|         9|   product_9|   70|   62046|         9|    15115|              505|\n|        10|  product_10|   28|   86864|        10|    35344|              693|\n|        11|  product_11|  113|  290916|        11|    47385|              787|\n+----------+------------+-----+--------+----------+---------+-----------------+\n\n+------------+\n|product_name|\n+------------+\n| product_106|\n| product_117|\n| product_363|\n| product_712|\n| product_843|\n| product_897|\n| product_923|\n|product_1466|\n|product_1507|\n|product_1514|\n+------------+\n\n"]}],"execution_count":0},{"cell_type":"markdown","source":["## Task 2: Spark ML (10m)"],"metadata":{"id":"4fziMyvTxnQg","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2551ab92-377c-4492-9d99-258610b143a1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"metadata":{"id":"wtocOKQXxnQg","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2ebc093d-9256-4e99-85d3-3d36b50a6053","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["bank_train_location = \"/FileStore/tables/bank_train.csv\"\nbank_test_location = \"/FileStore/tables/bank_test.csv\"\nfile_type = \"csv\"\n\n# CSV options\ninfer_schema = \"true\"\nfirst_row_is_header = \"true\"\ndelimiter = \",\"\n\n# The applied options are for CSV files. For other file types, these will be ignored.\nbank_train = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(bank_train_location)\n\nbank_test = spark.read.format(file_type) \\\n  .option(\"inferSchema\", infer_schema) \\\n  .option(\"header\", first_row_is_header) \\\n  .option(\"sep\", delimiter) \\\n  .load(bank_test_location)"],"metadata":{"id":"lQB18KhnxnQg","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2eee140e-773a-4e76-9f6c-40e809e136b0","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Build ML model to predict whether the customer will subscribe bank deposit service or not. Train the model using training set and evaluate the model performance (e.g. accuracy) using testing set. \n* You can explore different methods to pre-process the data and select proper features\n* You can utilize different machine learning models and tune model hyperparameters\n* Present the final testing accuracy."],"metadata":{"id":"YTZevHlAxnQg","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"98477bc0-fdf9-4585-8cf2-24b4b0ebc3f1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# TASK: Build ML model to predict whether the customer will subscribe bank deposit service or not. \n\n\"\"\"\nPossible parameters to use\n\nage:integer              --> needed\nmarital:string           --> need convert to numeric\neducation:string         --> need convert to numeric\ndefault:string           --> need convert to numeric\nbalance:integer          --> needed\nhousing:string           --> need convert to numeric\nloan:string              --> need convert to numeric\nduration:integer         --> needed\ncampaign:integer         --> needed\npdays:integer            --> needed\nprevious:integer         --> needed\npoutcome:string          --> need convert to numeric\nlabel:integer            --> target variable\n\njob:string               --> not needed\ncontact:string           --> not needed\nday:integer              --> not needed\nmonth:string             --> not needed\n\"\"\"\n\n# data preparation (4m)\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml import Pipeline\n\nconvert_marital = StringIndexer(\n    inputCol = \"marital\",\n    outputCol = \"marital_index\")\n\nconvert_education = StringIndexer(\n    inputCol = \"education\",\n    outputCol = \"education_index\")\n\nconvert_default = StringIndexer(\n    inputCol = \"default\",\n    outputCol = \"default_index\")\n\nconvert_housing = StringIndexer(\n    inputCol = \"housing\",\n    outputCol = \"housing_index\")\n\nconvert_loan = StringIndexer(\n    inputCol = \"loan\",\n    outputCol = \"loan_index\")\n\nconvert_poutcome = StringIndexer(\n    inputCol = \"poutcome\",\n    outputCol = \"poutcome_index\")\n\n\n\ndata_prep_pipeline = Pipeline(stages=[convert_marital, convert_education, convert_default, convert_housing, convert_loan, convert_poutcome])\n\npipeline_model_train = data_prep_pipeline.fit(bank_train)\npipeline_model_test = data_prep_pipeline.fit(bank_test)\n\nupdated_bank_train = pipeline_model_train.transform(bank_train)\nupdated_bank_test = pipeline_model_test.transform(bank_test)\n\nupdated_bank_train = updated_bank_train.drop(\"marital\", \"education\", \"default\", \"housing\", \"loan\", \"poutcome\", \"job\", \"contact\", \"day\", \"month\")\nupdated_bank_test = updated_bank_test.drop(\"marital\", \"education\", \"default\", \"housing\", \"loan\", \"poutcome\", \"job\", \"contact\", \"day\", \"month\")\n\n\nrequired_features = updated_bank_train.schema.names\nrequired_features.remove(\"label\")\nprint(required_features)\n\nassembler_train = VectorAssembler(inputCols=required_features, outputCol='features')\nassembler_test = VectorAssembler(inputCols=required_features, outputCol='features')\n\nupdated_bank_train = assembler_train.transform(updated_bank_train)\nupdated_bank_test = assembler_test.transform(updated_bank_test)\n\nupdated_bank_train.show()\nupdated_bank_test.show()\n\n\n\n\n\n"],"metadata":{"id":"iey06VQfxnQg","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e07aaf5a-6fb8-425a-a3c9-f52e04e49828","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["['age', 'balance', 'duration', 'campaign', 'pdays', 'previous', 'marital_index', 'education_index', 'default_index', 'housing_index', 'loan_index', 'poutcome_index']\n+---+-------+--------+--------+-----+--------+-----+-------------+---------------+-------------+-------------+----------+--------------+--------------------+\n|age|balance|duration|campaign|pdays|previous|label|marital_index|education_index|default_index|housing_index|loan_index|poutcome_index|            features|\n+---+-------+--------+--------+-----+--------+-----+-------------+---------------+-------------+-------------+----------+--------------+--------------------+\n| 45|   2033|      48|       4|   -1|       0|    0|          0.0|            3.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|\n| 56|    202|     178|       2|   -1|       0|    0|          0.0|            2.0|          0.0|          1.0|       0.0|           0.0|[56.0,202.0,178.0...|\n| 50|    799|      63|       1|   -1|       0|    0|          1.0|            0.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,6]...|\n| 58|   1464|      53|      29|   -1|       0|    0|          0.0|            0.0|          0.0|          1.0|       1.0|           0.0|[58.0,1464.0,53.0...|\n| 43|  11891|     821|       5|  242|       1|    1|          1.0|            1.0|          0.0|          0.0|       0.0|           2.0|[43.0,11891.0,821...|\n| 61|    938|     392|       2|  183|       3|    1|          0.0|            0.0|          0.0|          0.0|       0.0|           2.0|[61.0,938.0,392.0...|\n| 40|    275|     409|       4|   -1|       0|    0|          2.0|            0.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,6]...|\n| 52|    961|     222|       1|  553|       4|    1|          0.0|            0.0|          0.0|          0.0|       1.0|           1.0|[52.0,961.0,222.0...|\n| 36|    953|      38|       1|   -1|       0|    0|          0.0|            0.0|          0.0|          1.0|       0.0|           0.0|(12,[0,1,2,3,4,9]...|\n| 60|   1047|     173|       3|  279|       4|    1|          0.0|            0.0|          0.0|          0.0|       0.0|           2.0|[60.0,1047.0,173....|\n| 37|    187|     165|       1|   -1|       0|    0|          0.0|            0.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4],[...|\n| 33|    191|     678|       4|  209|       1|    0|          1.0|            1.0|          0.0|          0.0|       1.0|           1.0|[33.0,191.0,678.0...|\n| 31|    216|      47|       1|   -1|       0|    0|          0.0|            1.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|\n| 54|      0|     464|       5|  192|       8|    1|          0.0|            0.0|          0.0|          0.0|       0.0|           3.0|(12,[0,2,3,4,5,11...|\n| 47|    600|     290|      15|   -1|       0|    1|          0.0|            1.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|\n| 21|     71|     169|       2|   -1|       0|    1|          1.0|            0.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,6]...|\n| 43|      8|      95|       4|   -1|       0|    0|          0.0|            1.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|\n| 63|  18016|     371|       1|   -1|       0|    1|          0.0|            0.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4],[...|\n| 48|      0|      85|       1|  168|       2|    0|          0.0|            3.0|          0.0|          1.0|       0.0|           1.0|[48.0,0.0,85.0,1....|\n| 53|   1796|     295|       1|   91|       2|    1|          0.0|            0.0|          0.0|          0.0|       0.0|           2.0|[53.0,1796.0,295....|\n+---+-------+--------+--------+-----+--------+-----+-------------+---------------+-------------+-------------+----------+--------------+--------------------+\nonly showing top 20 rows\n\n+---+-------+--------+--------+-----+--------+-----+-------------+---------------+-------------+-------------+----------+--------------+--------------------+\n|age|balance|duration|campaign|pdays|previous|label|marital_index|education_index|default_index|housing_index|loan_index|poutcome_index|            features|\n+---+-------+--------+--------+-----+--------+-----+-------------+---------------+-------------+-------------+----------+--------------+--------------------+\n| 45|   2220|     128|       2|   -1|       0|    0|          0.0|            1.0|          0.0|          1.0|       0.0|           0.0|[45.0,2220.0,128....|\n| 36|   3623|      71|       1|  378|       1|    1|          1.0|            0.0|          0.0|          0.0|       0.0|           2.0|[36.0,3623.0,71.0...|\n| 37|   1506|     101|       3|   80|       3|    0|          0.0|            2.0|          0.0|          0.0|       0.0|           2.0|[37.0,1506.0,101....|\n| 65|    952|     255|       1|   96|       1|    1|          0.0|            0.0|          0.0|          0.0|       0.0|           2.0|[65.0,952.0,255.0...|\n| 37|     40|    1033|       4|   -1|       0|    1|          0.0|            1.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|\n| 45|   -395|     470|       1|   -1|       0|    1|          2.0|            1.0|          0.0|          1.0|       0.0|           0.0|[45.0,-395.0,470....|\n| 51|   1573|      72|      18|   -1|       0|    0|          0.0|            0.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4],[...|\n| 39|      0|    1975|       5|   -1|       0|    1|          1.0|            2.0|          0.0|          1.0|       1.0|           0.0|[39.0,0.0,1975.0,...|\n| 34|    606|      97|       1|   -1|       0|    1|          0.0|            1.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|\n| 30|    596|     125|       2|   -1|       0|    0|          1.0|            1.0|          0.0|          0.0|       0.0|           0.0|[30.0,596.0,125.0...|\n| 60|   1163|     470|       8|   -1|       0|    1|          0.0|            2.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|\n| 45|     51|      67|       8|   -1|       0|    0|          2.0|            0.0|          0.0|          1.0|       0.0|           0.0|[45.0,51.0,67.0,8...|\n| 30|    140|     760|       1|   -1|       0|    1|          1.0|            0.0|          0.0|          1.0|       0.0|           0.0|[30.0,140.0,760.0...|\n| 38|   2496|     193|       1|   -1|       0|    0|          1.0|            1.0|          0.0|          0.0|       0.0|           0.0|[38.0,2496.0,193....|\n| 37|      0|      93|      14|   -1|       0|    0|          0.0|            1.0|          1.0|          1.0|       0.0|           0.0|[37.0,0.0,93.0,14...|\n| 41|   6596|      88|       1|   -1|       0|    0|          0.0|            2.0|          0.0|          1.0|       0.0|           0.0|[41.0,6596.0,88.0...|\n| 45|   3133|     804|       1|   -1|       0|    1|          0.0|            3.0|          0.0|          1.0|       1.0|           0.0|[45.0,3133.0,804....|\n| 33|    193|     132|       2|   -1|       0|    0|          1.0|            1.0|          0.0|          0.0|       0.0|           0.0|[33.0,193.0,132.0...|\n| 31|    985|     997|       1|   57|       2|    1|          1.0|            1.0|          0.0|          1.0|       0.0|           1.0|[31.0,985.0,997.0...|\n| 49|    271|      18|       6|   -1|       0|    0|          0.0|            1.0|          0.0|          1.0|       0.0|           0.0|[49.0,271.0,18.0,...|\n+---+-------+--------+--------+-----+--------+-----+-------------+---------------+-------------+-------------+----------+--------------+--------------------+\nonly showing top 20 rows\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# model building (4m)\n\n\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import HashingTF, Tokenizer\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n\nrf = RandomForestClassifier(labelCol=\"label\",\n                            featuresCol=\"features\",\n                            maxDepth=5)\n\nmodel = rf.fit(updated_bank_train)\n\n"],"metadata":{"id":"PsIotb9ExnQh","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a04b59e4-6197-451c-8071-52526a5a724f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# model evaluation (2m)\n\npredictions = model.transform(updated_bank_test)\npredictions.show()\n\nevaluator = MulticlassClassificationEvaluator(\n    labelCol='label', \n    predictionCol='prediction', \n    metricName='accuracy')\n\naccuracy = evaluator.evaluate(predictions)\nprint('Test Accuracy = ', accuracy)"],"metadata":{"id":"OC5ufJqAxnQh","application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"80e1c949-8291-45be-8872-c0310777c6fa","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+---+-------+--------+--------+-----+--------+-----+-------------+---------------+-------------+-------------+----------+--------------+--------------------+--------------------+--------------------+----------+\n|age|balance|duration|campaign|pdays|previous|label|marital_index|education_index|default_index|housing_index|loan_index|poutcome_index|            features|       rawPrediction|         probability|prediction|\n+---+-------+--------+--------+-----+--------+-----+-------------+---------------+-------------+-------------+----------+--------------+--------------------+--------------------+--------------------+----------+\n| 45|   2220|     128|       2|   -1|       0|    0|          0.0|            1.0|          0.0|          1.0|       0.0|           0.0|[45.0,2220.0,128....|[16.5639948298713...|[0.82819974149356...|       0.0|\n| 36|   3623|      71|       1|  378|       1|    1|          1.0|            0.0|          0.0|          0.0|       0.0|           2.0|[36.0,3623.0,71.0...|[9.45194809601512...|[0.47259740480075...|       1.0|\n| 37|   1506|     101|       3|   80|       3|    0|          0.0|            2.0|          0.0|          0.0|       0.0|           2.0|[37.0,1506.0,101....|[7.91800871507096...|[0.39590043575354...|       1.0|\n| 65|    952|     255|       1|   96|       1|    1|          0.0|            0.0|          0.0|          0.0|       0.0|           2.0|[65.0,952.0,255.0...|[1.93422717047112...|[0.09671135852355...|       1.0|\n| 37|     40|    1033|       4|   -1|       0|    1|          0.0|            1.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|[4.57592447027177...|[0.22879622351358...|       1.0|\n| 45|   -395|     470|       1|   -1|       0|    1|          2.0|            1.0|          0.0|          1.0|       0.0|           0.0|[45.0,-395.0,470....|[7.39544687898916...|[0.36977234394945...|       1.0|\n| 51|   1573|      72|      18|   -1|       0|    0|          0.0|            0.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4],[...|[16.2471142404815...|[0.81235571202407...|       0.0|\n| 39|      0|    1975|       5|   -1|       0|    1|          1.0|            2.0|          0.0|          1.0|       1.0|           0.0|[39.0,0.0,1975.0,...|[5.1620656875064,...|[0.25810328437531...|       1.0|\n| 34|    606|      97|       1|   -1|       0|    1|          0.0|            1.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|[15.9222614765479...|[0.79611307382739...|       0.0|\n| 30|    596|     125|       2|   -1|       0|    0|          1.0|            1.0|          0.0|          0.0|       0.0|           0.0|[30.0,596.0,125.0...|[15.3176864561590...|[0.76588432280795...|       0.0|\n| 60|   1163|     470|       8|   -1|       0|    1|          0.0|            2.0|          0.0|          0.0|       0.0|           0.0|(12,[0,1,2,3,4,7]...|[5.70787712924688...|[0.28539385646234...|       1.0|\n| 45|     51|      67|       8|   -1|       0|    0|          2.0|            0.0|          0.0|          1.0|       0.0|           0.0|[45.0,51.0,67.0,8...|[17.1216197218437...|[0.85608098609218...|       0.0|\n| 30|    140|     760|       1|   -1|       0|    1|          1.0|            0.0|          0.0|          1.0|       0.0|           0.0|[30.0,140.0,760.0...|[4.82765927949970...|[0.24138296397498...|       1.0|\n| 38|   2496|     193|       1|   -1|       0|    0|          1.0|            1.0|          0.0|          0.0|       0.0|           0.0|[38.0,2496.0,193....|[12.2360408177612...|[0.61180204088806...|       0.0|\n| 37|      0|      93|      14|   -1|       0|    0|          0.0|            1.0|          1.0|          1.0|       0.0|           0.0|[37.0,0.0,93.0,14...|[17.5022193389605...|[0.87511096694802...|       0.0|\n| 41|   6596|      88|       1|   -1|       0|    0|          0.0|            2.0|          0.0|          1.0|       0.0|           0.0|[41.0,6596.0,88.0...|[16.6210569148197...|[0.83105284574098...|       0.0|\n| 45|   3133|     804|       1|   -1|       0|    1|          0.0|            3.0|          0.0|          1.0|       1.0|           0.0|[45.0,3133.0,804....|[5.25312140120503...|[0.26265607006025...|       1.0|\n| 33|    193|     132|       2|   -1|       0|    0|          1.0|            1.0|          0.0|          0.0|       0.0|           0.0|[33.0,193.0,132.0...|[15.3390640000381...|[0.76695320000190...|       0.0|\n| 31|    985|     997|       1|   57|       2|    1|          1.0|            1.0|          0.0|          1.0|       0.0|           1.0|[31.0,985.0,997.0...|[5.19013922589410...|[0.25950696129470...|       1.0|\n| 49|    271|      18|       6|   -1|       0|    0|          0.0|            1.0|          0.0|          1.0|       0.0|           0.0|[49.0,271.0,18.0,...|[17.4431105132380...|[0.87215552566190...|       0.0|\n+---+-------+--------+--------+-----+--------+-----+-------------+---------------+-------------+-------------+----------+--------------+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\nTest Accuracy =  0.7989252127183162\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8a71087d-70af-40d8-98a4-66774c5ebc7a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"application/vnd.databricks.v1+notebook":{"notebookName":"cs4225_a2_databricks_student_version","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":170246883326447}},"nbformat":4,"nbformat_minor":0}
